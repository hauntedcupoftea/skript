{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Welcome to Skript.\n",
    "This project is the work of Anand Chauhan, Vasu Jain, and Aayush Gupta. Students enrolled at Bennett University, for the purpose of a Probability and Statistics Hackathon as part of their curriculum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-06 02:11:59.188344: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-11-06 02:11:59.188497: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-11-06 02:11:59.188533: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-11-06 02:11:59.189638: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-11-06 02:11:59.189714: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2022-11-06 02:11:59.189825: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-11-06 02:11:59.189910: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5889 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2070 Super, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "# importing all libraries in one cell\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import tensorflow as tf\n",
    "import spacy\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.compat.v1.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the sample dataset, created by Vasu Jain.\n",
    "dataset = pd.read_csv('Speeches.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let the user select a speech and seperate every sentence from it.\n",
    "f = open('sample.txt', 'r', encoding='UTF8')\n",
    "sample = np.array(re.split(r'(\\. )|(\\n)', f.read()))\n",
    "sample = sample[sample != np.array(None)]\n",
    "cleansample = np.array([i for i in sample if len(i) > 6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load spacy NLP model\n",
    "spacy.prefer_gpu()\n",
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text     POS    TAG    Dep    POS explained        tag explained \n",
      "Five     NUM    CD     nummod numeral              cardinal number\n",
      "score    NOUN   NN     compound noun                 noun, singular or mass\n",
      "years    NOUN   NNS    npadvmod noun                 noun, plural\n",
      "ago      ADV    RB     advmod adverb               adverb\n",
      ",        PUNCT  ,      punct  punctuation          punctuation mark, comma\n",
      "a        DET    DT     det    determiner           determiner\n",
      "great    ADJ    JJ     amod   adjective            adjective (English), other noun-modifier (Chinese)\n",
      "American ADJ    JJ     nsubj  adjective            adjective (English), other noun-modifier (Chinese)\n",
      "in       ADP    IN     prep   adposition           conjunction, subordinating or preposition\n",
      "whose    DET    WP$    poss   determiner           wh-pronoun, possessive\n",
      "symbolic ADJ    JJ     amod   adjective            adjective (English), other noun-modifier (Chinese)\n",
      "shadow   NOUN   NN     pobj   noun                 noun, singular or mass\n",
      "we       PRON   PRP    nsubj  pronoun              pronoun, personal\n",
      "stand    VERB   VBP    relcl  verb                 verb, non-3rd person singular present\n",
      "today    NOUN   NN     npadvmod noun                 noun, singular or mass\n",
      ",        PUNCT  ,      punct  punctuation          punctuation mark, comma\n",
      "signed   VERB   VBD    ROOT   verb                 verb, past tense\n",
      "the      DET    DT     det    determiner           determiner\n",
      "Emancipation PROPN  NNP    compound proper noun          noun, proper singular\n",
      "Proclamation PROPN  NNP    dobj   proper noun          noun, proper singular\n"
     ]
    }
   ],
   "source": [
    "# a sample of tokenizing with Spacy\n",
    "doc = nlp(str(cleansample[1]))\n",
    "\n",
    "print(f\"{'text':{8}} {'POS':{6}} {'TAG':{6}} {'Dep':{6}} {'POS explained':{20}} {'tag explained'} \")\n",
    "for token in doc:\n",
    "    print(f'{token.text:{8}} {token.pos_:{6}} {token.tag_:{6}} {token.dep_:{6}} {spacy.explain(token.pos_):{20}} {spacy.explain(token.tag_)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a tangent, making a numpy array with every individual word.\n",
    "words = [i.split() for i in cleansample]\n",
    "punc = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
    "cleanwords = []\n",
    "for i in words:\n",
    "    for x in i:\n",
    "        x.replace(punc, \"\")\n",
    "        cleanwords.append(x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count for shall is: 5\n",
      "count for will is: 27\n",
      "count for would is: 2\n",
      "count for must is: 8\n"
     ]
    }
   ],
   "source": [
    "# a simple script to detect persuasive sentences\n",
    "results = dict(Counter(cleanwords))\n",
    "modal = ['shall', 'should', 'will', 'would', 'must', 'ought', 'used', 'need', 'dare']\n",
    "for i in modal:\n",
    "    try:\n",
    "        print(f\"count for {i} is: {results[i]}\")\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizing every word with the NLP model.\n",
    "rawspeech = \" \".join(cleansample.tolist())\n",
    "proc = nlp(rawspeech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6354889093022426\n",
      "0.6973077654838562\n"
     ]
    }
   ],
   "source": [
    "# Experimental cell to find the best approach to find all 5 scores.\n",
    "auxcount = 0\n",
    "modcount = 0\n",
    "for i in proc:\n",
    "    if i.dep_ == 'aux':\n",
    "        auxcount += 1\n",
    "    if i.text in modal:\n",
    "        modcount += 1\n",
    "\n",
    "PERscore = np.sqrt(modcount/auxcount)\n",
    "print(PERscore)\n",
    "\n",
    "print(proc.similarity(nlp(\"progressive\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Date</th>\n",
       "      <th>Author</th>\n",
       "      <th>Speech</th>\n",
       "      <th>cleansample</th>\n",
       "      <th>cleanwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Eighth Annual Message to Congress</td>\n",
       "      <td>7-12-1796</td>\n",
       "      <td>George Washington</td>\n",
       "      <td>Fellow Citizens of the Senate and House of Rep...</td>\n",
       "      <td>[Fellow Citizens of the Senate and House of Re...</td>\n",
       "      <td>[fellow, citizens, of, the, senate, and, house...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Declaration of Independence Anniversary Commem...</td>\n",
       "      <td>05-07-1926</td>\n",
       "      <td>Calvin Coolidge</td>\n",
       "      <td>Fellow Countrymen:\\nWe meet to celebrate the b...</td>\n",
       "      <td>[Fellow Countrymen:, We meet to celebrate the ...</td>\n",
       "      <td>[fellow, countrymen:, we, meet, to, celebrate,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Address on the Nuclear Test Ban Treaty</td>\n",
       "      <td>26-07-1963</td>\n",
       "      <td>John F. Kennedy</td>\n",
       "      <td>Good evening, my fellow citizens:\\nI speak to ...</td>\n",
       "      <td>[Good evening, my fellow citizens:, I speak to...</td>\n",
       "      <td>[good, evening,, my, fellow, citizens:, i, spe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Inaugural Address</td>\n",
       "      <td>20-01-2017</td>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>Chief Justice Roberts, President Carter, Presi...</td>\n",
       "      <td>[Chief Justice Roberts, President Carter, Pres...</td>\n",
       "      <td>[chief, justice, roberts,, president, carter,,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gettysburg Address</td>\n",
       "      <td>19-11-1863</td>\n",
       "      <td>Abraham Lincoln</td>\n",
       "      <td>Four score and seven years ago our fathers bro...</td>\n",
       "      <td>[Four score and seven years ago our fathers br...</td>\n",
       "      <td>[four, score, and, seven, years, ago, our, fat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title        Date  \\\n",
       "0                  Eighth Annual Message to Congress   7-12-1796   \n",
       "1  Declaration of Independence Anniversary Commem...  05-07-1926   \n",
       "2             Address on the Nuclear Test Ban Treaty  26-07-1963   \n",
       "3                                  Inaugural Address  20-01-2017   \n",
       "4                                 Gettysburg Address  19-11-1863   \n",
       "\n",
       "              Author                                             Speech  \\\n",
       "0  George Washington  Fellow Citizens of the Senate and House of Rep...   \n",
       "1    Calvin Coolidge  Fellow Countrymen:\\nWe meet to celebrate the b...   \n",
       "2    John F. Kennedy  Good evening, my fellow citizens:\\nI speak to ...   \n",
       "3       Donald Trump  Chief Justice Roberts, President Carter, Presi...   \n",
       "4    Abraham Lincoln  Four score and seven years ago our fathers bro...   \n",
       "\n",
       "                                         cleansample  \\\n",
       "0  [Fellow Citizens of the Senate and House of Re...   \n",
       "1  [Fellow Countrymen:, We meet to celebrate the ...   \n",
       "2  [Good evening, my fellow citizens:, I speak to...   \n",
       "3  [Chief Justice Roberts, President Carter, Pres...   \n",
       "4  [Four score and seven years ago our fathers br...   \n",
       "\n",
       "                                          cleanwords  \n",
       "0  [fellow, citizens, of, the, senate, and, house...  \n",
       "1  [fellow, countrymen:, we, meet, to, celebrate,...  \n",
       "2  [good, evening,, my, fellow, citizens:, i, spe...  \n",
       "3  [chief, justice, roberts,, president, carter,,...  \n",
       "4  [four, score, and, seven, years, ago, our, fat...  "
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a script that cleans every speech in the dataset and adds it to the dataframe\n",
    "# megasample and megawords contain the megaArray that can just be slotted in into the dataframe\n",
    "megasample = []\n",
    "megawords = []\n",
    "# loop the cleaning script across all the speeches of the dataset.\n",
    "# this code can also be used as general cleaning of input data.\n",
    "for i in range(len(dataset)):\n",
    "    cleansample = []\n",
    "    cleanwords = []\n",
    "    sample = np.array(re.split(r'(\\. )|(\\n)|(;)', dataset.loc[i, 'Speech']))\n",
    "    sample = sample[sample != np.array(None)]\n",
    "    cleansample = np.array([i for i in sample if len(i) > 4])\n",
    "    words = [i.split() for i in cleansample]\n",
    "    punc = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
    "    for i in words:\n",
    "        for x in i:\n",
    "            x.replace(punc, \"\")\n",
    "            cleanwords.append(x.lower())\n",
    "    megasample.append(cleansample)\n",
    "    megawords.append(cleanwords)\n",
    "    \n",
    "    \n",
    "dataset['cleansample'] = megasample\n",
    "dataset['cleanwords'] = megawords\n",
    "dataset.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6314624a9b716fa5073b1b74923d7a0fe6a712a100f298bdf1d68454cdfed291"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
